{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1-2: Linear Regression with Multiple Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will implement linear regression with multiple variables to predict the prices of houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex1data2.txt contains a dataset of housing prices, including the size of the house (in square feet), the number of bedrooms, and the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples from the dataset:\n",
      "\n",
      "x = [2104.    3.] , y = 399900.0\n",
      "x = [1600.    3.] , y = 329900.0\n",
      "x = [2400.    3.] , y = 369000.0\n",
      "x = [1416.    2.] , y = 232000.0\n",
      "x = [3000.    4.] , y = 539900.0\n",
      "x = [1985.    4.] , y = 299900.0\n",
      "x = [1534.    3.] , y = 314900.0\n",
      "x = [1427.    3.] , y = 198999.0\n",
      "x = [1380.    3.] , y = 212000.0\n",
      "x = [1494.    3.] , y = 242500.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.loadtxt(open(\"ex1data2.txt\", \"r\"), delimiter=\",\")\n",
    "X = data[:, 0:2]\n",
    "y = data[:, 2]\n",
    "m = len(y)\n",
    "\n",
    "# Print out some data points\n",
    "print('First 10 examples from the dataset:\\n')\n",
    "for i in range(10):\n",
    "    print('x =', X[i, ], ', y =', y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the house sizes (first colums in X) are about 1000 times the number of bedrooms (second column in X). The feature_normalize() normalizes the input features and set then to zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "        Features to be normalized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_norm : ndarray, shape (n_samples, n_features)\n",
    "        A normalized version of X where the mean value of each feature is 0 and the standard deviation is 1.\n",
    "    mu : ndarray, shape (n_features,)\n",
    "        The mean value.\n",
    "    sigma : ndarray, shape (n_features,)\n",
    "        The standard deviation.\n",
    "    \"\"\"\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0, ddof=1)\n",
    "    X_norm = (X - mu) / sigma\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize X and add intercept term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, mu, sigma = feature_normalize(X)\n",
    "X = np.hstack((np.ones((m, 1)), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running gradient descent, the parameters are initialized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some alpha value\n",
    "alpha = 0.15\n",
    "num_iters = 400\n",
    "\n",
    "# Init theta and run gradient descent\n",
    "theta = np.zeros(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute_cost_multi() computes the cost for linear regression with multiple variables in a vectorized way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_multi(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression with multiple variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "        Training data, where n_samples is the number of samples and n_features is the number of features.\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels.\n",
    "    theta : ndarray, shape (n_features,)\n",
    "        Linear regression parameter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    J : numpy.float64\n",
    "        The cost of using theta as the parameter for linear regression to fit the data points in X and y.\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    diff = X.dot(theta) - y\n",
    "    J = 1.0 / (2 * m) * diff.T.dot(diff)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient_descent_multi() performs the gradient descent to learn theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_multi(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn theta.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "        Training data, where n_samples is the number of samples and n_features is the number of features.\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels.\n",
    "    theta : ndarray, shape (n_features,)\n",
    "        Initial linear regression parameter.\n",
    "    alpha : float\n",
    "        Learning rate.\n",
    "    num_iters: int\n",
    "        Number of iteration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta : ndarray, shape (n_features,)\n",
    "        Linear regression parameter.\n",
    "    J_history: ndarray, shape (num_iters,)\n",
    "        Cost history.\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    J_history = np.zeros(num_iters)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        theta -= alpha / m * ((X.dot(theta) - y).T.dot(X))\n",
    "        J_history[i] = compute_cost_multi(X, y, theta)\n",
    "\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gradient descent with given parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, J_history = gradient_descent_multi(X, y, theta, alpha, num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot convergence graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_iters + 1), J_history, color='b')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost J')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from gradient descent:\n",
      "[340412.65957447 110631.0502787   -6649.47427067]\n"
     ]
    }
   ],
   "source": [
    "print('Theta computed from gradient descent:')\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the price of a 1650 sq-ft, 3 br house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price of a 1650 sq-ft, 3 br house: 293081.46433492796\n"
     ]
    }
   ],
   "source": [
    "normalize_test_data = ((np.array([1650, 3]) - mu) / sigma)\n",
    "normalize_test_data = np.hstack((np.ones(1), normalize_test_data))\n",
    "price = normalize_test_data.dot(theta)\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house:', price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Normal Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will math out the parameter theta by using normal equation.\n",
    "\n",
    "We use the same data as the gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open(\"ex1data2.txt\", \"r\"), delimiter=\",\")\n",
    "X = data[:, 0:2]\n",
    "y = data[:, 2]\n",
    "m = len(y)\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.hstack((np.ones((m, 1)), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal_eqn() computes the closed-form solution to linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_eqn(X, y):\n",
    "    \"\"\"\n",
    "    Computes the closed-form solution to linear regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "        Training data, where n_samples is the number of samples and n_features is the number of features.\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta : ndarray, shape (n_features,)\n",
    "        The closed-form solution to linear regression using the normal equations.\n",
    "    \"\"\"\n",
    "    theta = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the parameters from the normal equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from the normal equations: \n",
      "[89597.90954355   139.21067402 -8738.01911255]\n"
     ]
    }
   ],
   "source": [
    "theta = normal_eqn(X, y)\n",
    "print('Theta computed from the normal equations: ')\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the price of a 1650 sq-ft, 3 br house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price of a 1650 sq-ft, 3 br house (using normal equations): 293081.4643349717\n"
     ]
    }
   ],
   "source": [
    "price = np.array([1, 1650, 3]).dot(theta)\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house (using normal equations):', price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
